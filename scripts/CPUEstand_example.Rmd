---
title: 'CPUE standartisation using GLM_Example StockC'
author: Eglė Jakubavičiūtė and Asta Audzijonytė
output:
  html_document: default
  pdf_document: default
---
### load libraries

```{r setup, include=FALSE, eval = T, echo = F, message = F, warning = F}

rm(list = ls()) # clear memory
library(gplots)
library(ggplot2)
library(dplyr)
library(tidyverse)
library(lubridate)
library(data.table)
library(nlme)
library(gamm4)
library(statmod)
library(MuMIn)
library(tweedie)
library(ggfortify)
library(ggeffects)
library(sjPlot)
library(ggpubr)
library(effects)

#install.packages("remotes")
#remotes::install_github("haddonm/r4cpue")
library(r4cpue)

```



###import and explore dataset

```{r}

#import dataset
stockC <- read.csv(file = 'stockC2.csv', fileEncoding="UTF-8-BOM") 

#check how it looks
head(stockC)
str(stockC)

#in this dataset, net length and soak time are indicated as ordered factors, so make sure they are treated like that. Also, Year must be a factor

stockC$Year<-as.factor(stockC$Year)
stockC$Soak_time_Or<-as.ordered(stockC$Soak_time_Or)
stockC$Net_length_Or<-as.ordered(stockC$Net_length_Or)
stockC$season <- as.factor(stockC$season)

#which seasons do we have
unique(stockC$season)

#balance among seasons 
table(stockC$season)

#how many locations
unique(stockC$Location)
#balance among locations
table(stockC$Location)

#gillnet categories and balance 
unique(stockC$Gillnet_category)
table(stockC$Gillnet_category)

#probably we should remove category "other" in gillnets
stockC<-stockC %>% filter (Gillnet_category!="other")



```


###Build models 
Start GLM, with distribution family tweedie, which allows many zeros in the distribution. 


```{r}
#build model with all factors 

modC1<- glm(Catch_g~Year + season + Location + Gillnet_category + Net.mesh.gr + Net_length_Or +Soak_time_Or, family=tweedie(var.power=1.1, link.power=0), data=stockC)
summary(modC1)

#Can we drop anything? I.e. is model without certain variable significantly different from the one that includes it?
drop1(modC1, test = "F")

#yes, soak time is not signif

AICtweedie(modC1)  
modEvA::Dsquared(modC1) *100  # % of explained deviance

#Soak time is not signif, so try without it and then compare the models 

modC2<- glm(Catch_g~Year + season + Location + Gillnet_category + Net.mesh.gr + Net_length_Or,  family=tweedie(var.power=1.1, link.power=0), data=stockC)
summary(modC2)
AICtweedie(modC2) 

modEvA::Dsquared(modC2) *100  # % of explained deviance

AICtweedie(modC2)- AICtweedie(modC1)

#AIC is the lower for modC1 so consider it the best model



```

#Extract coefficients and plot standardised CPUE

```{r}
##extract coefficients. We can use a little function scaleCE that will scale the cpue against the first Year 
tt <- summary(modC1)$coefficients  # combine these with empty first Year
tt2 <- rbind(c(0,0,0,0), tt[grep("Year",rownames(tt)),])
tt3 <- cbind(tt2, exp(tt2[,"Estimate"]), scaleCE(exp(tt2[,"Estimate"])))
yrs<- c(1991:2021)
cpue_stand <- cbind(tt3, yrs)
colnames(cpue_stand) <- c( "Estimate", "StdError", "t value" ,"Pr(>|t|)" , "Exp_estimate" ,"Scaled_estimate", "Year")
rm(tt, tt2, tt3)

cpue_stand <- as.data.frame(cpue_stand)

#Plot - need to start the Year before the dataset as it uses that to scale to
plot(cpue_stand$Year, cpue_stand$Scaled_estimate, ylab="Standardised CPUE", main="Stock C", xlab="Year",pch= 19)

#ggplot
ggplot(cpue_stand, aes(Year, Scaled_estimate)) +      
  geom_point(data = cpue_stand, aes(x = Year, y = Scaled_estimate), size=2) +
  #geom_errorbar(data = cpue_stand, aes(ymin = Scaled_estimate, ymax = Scaled_estimate+StdError)) +
    ylab("Standardised CPUE") +
  xlab("") +
   ggtitle("") +
  geom_smooth(method = "loess") +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black")) +
  theme(axis.text=element_text(size=14),
        axis.title=element_text(size=14))

#save
#write.csv(cpue_stand, "cpue_standStockC1.csv")


```

#Diagnostics

```{r}

#plot model coefficients
plot_model(modC1)

#plot effects
plot(allEffects(modC1))

#Check residuals and outliers, try again without them if needed
#model diagnostics
autoplot(modC1, which = 1:6, label.size = 3)+ 
  theme_bw()

#outliers- quantitative detection

#leverage  distance
i_n = influence(modC1)$hat # calculate the influence of data points
which.max(i_n)   #shows which data point has the highest influence on the fitted model
stockC[1658,]

#Cook’s distance.
c_d = cooks.distance(modC1)
which.max(c_d)  ##shows which data point has the highest influence on the fitted model
stockC[1699,]
#stockC[1532,]

stockC<-stockC[-1699,]   #remove outlier from the dataset, and check how results have changed

```

